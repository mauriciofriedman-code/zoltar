# backend/ingest.py
import argparse
import shutil
from pathlib import Path

from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma

from backend.config import DOCS_DIR, CHROMA_DIR
from backend.llm_loader import get_embeddings


# ================================
# Carga de PDFs
# ================================
def load_all_pdfs(docs_dir: Path):
    """Carga todos los PDFs desde docs_dir y aÃ±ade metadatos."""
    docs = []
    for pdf_path in sorted(docs_dir.glob("**/*.pdf")):
        print(f"ğŸ“„ Cargando {pdf_path.name}...")
        loader = PyPDFLoader(str(pdf_path))
        pages = loader.load()

        # Metadatos personalizados segÃºn archivo
        if "s10639-023-12401-4" in pdf_path.name:
            title = ("Learning analytics dashboards are increasingly becoming about learning "
                     "and not just analytics â€“ A systematic review")
            authors = "Lucas Paulsen, Euan Lindsay"
        elif "s41239-023-00426-1" in pdf_path.name:
            title = "Role of AI chatbots in education: systematic literature review"
            authors = "Lasha Labadze, Maya Grigolia, Lela Machaidze"
        else:
            title = pdf_path.stem
            authors = "Autores desconocidos"

        # Asignar metadatos a cada pÃ¡gina
        for p in pages:
            p.metadata = p.metadata or {}
            p.metadata["title"] = title
            p.metadata["authors"] = authors
            p.metadata["doc_id"] = pdf_path.stem
        docs.extend(pages)

    return docs


# ================================
# Split de documentos
# ================================
def split_docs(docs, chunk_size=350, chunk_overlap=70):
    """Divide documentos en chunks con solapamiento."""
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        length_function=len,
    )
    return splitter.split_documents(docs)


# ================================
# Manejo del Ã­ndice
# ================================
def rebuild_chroma():
    """Elimina Ã­ndice existente de Chroma."""
    if CHROMA_DIR.exists():
        print("ğŸ§¹ Limpiando Ã­ndice Chromaâ€¦")
        shutil.rmtree(CHROMA_DIR)


def has_index() -> bool:
    """Revisa si ya existe un Ã­ndice persistente en CHROMA_DIR."""
    return CHROMA_DIR.exists() and any(CHROMA_DIR.glob("**/*"))


# ================================
# ConstrucciÃ³n de Ã­ndice
# ================================
def main(rebuild: bool = False):
    if rebuild:
        rebuild_chroma()

    if not DOCS_DIR.exists():
        raise FileNotFoundError(f"âŒ No existe {DOCS_DIR}. Coloca tus PDFs allÃ­.")

    print(f"ğŸ“‚ Cargando PDFs desde {DOCS_DIR}â€¦")
    raw_docs = load_all_pdfs(DOCS_DIR)
    if not raw_docs:
        raise RuntimeError("âŒ No se encontraron PDFs en data/docs")

    print("âœ‚ï¸ Troceando documentos (350/70)â€¦")
    chunks = split_docs(raw_docs)

    print(f"ğŸ“Š Total de pÃ¡ginas: {len(raw_docs)}")
    print(f"ğŸ“Š Total de chunks: {len(chunks)}")

    print("âš™ï¸ Generando embeddings y persistiendo en Chromaâ€¦")
    embeddings = get_embeddings()
    vectordb = Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        persist_directory=str(CHROMA_DIR),
    )
    vectordb.persist()
    print(f"âœ… Listo. Ãndice guardado en {CHROMA_DIR}")


def ensure_index():
    """Usado en startup: si no existe Ã­ndice, lo construye."""
    if has_index():
        print("âœ… Ãndice Chroma existente. No se reconstruye.")
        return
    print("â„¹ï¸ No hay Ã­ndice Chroma. CreÃ¡ndolo por primera vezâ€¦")
    main(rebuild=False)


# ================================
# CLI
# ================================
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--rebuild", action="store_true", help="Reconstruye el Ã­ndice desde cero"
    )
    args = parser.parse_args()

    if args.rebuild:
        main(rebuild=True)
    else:
        ensure_index()

